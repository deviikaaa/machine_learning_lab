{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c4a59be-8aa9-4642-811d-65e5ac262711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most specific hypothesis: ['Sunny', 'Warm', '?', 'Strong', '?', '?']\n"
     ]
    }
   ],
   "source": [
    "# 1. Implement and demonstrate the Find-S algorithm for finding the most specific hypothesis.\n",
    "\n",
    "def find_s(training_data):\n",
    "    # Initialize the most specific hypothesis\n",
    "    hypothesis = ['0'] * len(training_data[0][:-1])\n",
    "    \n",
    "    for example in training_data:\n",
    "        if example[-1] == \"yes\":  # Only consider positive examples\n",
    "            for i in range(len(hypothesis)):\n",
    "                if hypothesis[i] == '0':  # Initial assignment\n",
    "                    hypothesis[i] = example[i]\n",
    "                elif hypothesis[i] != example[i]:  # Generalize\n",
    "                    hypothesis[i] = '?'\n",
    "                    \n",
    "    return hypothesis\n",
    "\n",
    "# Example training data: (Sunny, Warm, Normal, Strong, Warm, Same) -> Yes/No\n",
    "training_data = [\n",
    "    (\"Sunny\", \"Warm\", \"Normal\", \"Strong\", \"Warm\", \"Same\", \"yes\"),\n",
    "    (\"Sunny\", \"Warm\", \"High\", \"Strong\", \"Warm\", \"Same\", \"yes\"),\n",
    "    (\"Rainy\", \"Cold\", \"High\", \"Strong\", \"Warm\", \"Change\", \"no\"),\n",
    "    (\"Sunny\", \"Warm\", \"High\", \"Strong\", \"Cool\", \"Change\", \"yes\")\n",
    "]\n",
    "\n",
    "# Find the most specific hypothesis\n",
    "hypothesis = find_s(training_data)\n",
    "print(\"Most specific hypothesis:\", hypothesis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63cff6db-bcd9-4e97-b653-db4923593ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Specific Hypothesis:\n",
      " ['Sunny', 'Warm', '?', 'Strong', '?', '?']\n",
      "\n",
      "Final General Hypothesis:\n",
      " [['?', '?', '?', 'Strong', '?', '?']]\n"
     ]
    }
   ],
   "source": [
    "# 2. Implement and demonstrate the Candidate Elimination algorithm using a data set stored as a .CSV file.\n",
    "\n",
    "import csv\n",
    "\n",
    "with open(\"dataset2.csv\") as f:\n",
    "    csv_file = csv.reader(f)\n",
    "    data = list(csv_file)\n",
    "\n",
    "specific = data[1][:-1]\n",
    "general = [['?' for _ in range(len(specific))] for _ in range(len(specific))]\n",
    "\n",
    "for i in data[1:]:\n",
    "    if i[-1] == \"Yes\":\n",
    "        for j in range(len(specific)):\n",
    "            if i[j] != specific[j]:\n",
    "                specific[j] = '?'\n",
    "                general[j][j] = '?'\n",
    "    elif i[-1] == \"No\":\n",
    "        for j in range(len(specific)):\n",
    "            if i[j] != specific[j]:\n",
    "                general[j][j] = '?'\n",
    "            else:\n",
    "                general[j][j] = specific[j]\n",
    "\n",
    "gh = [g for g in general if g != ['?' for _ in range(len(specific))]]\n",
    "\n",
    "print(\"\\nFinal Specific Hypothesis:\\n\", specific)\n",
    "print(\"\\nFinal General Hypothesis:\\n\", gh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e283b20b-5663-4268-9c85-e9a0a26d033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaning:\n",
      "      Name    Age   Salary Department\n",
      "0    Alice  30.00  50000.0         HR\n",
      "1      Bob  33.75  60000.0         IT\n",
      "2  Charlie  35.00  55000.0    Finance\n",
      "4      Eve  40.00  70000.0         IT\n",
      "\n",
      "Data after integration:\n",
      "      Name    Age   Salary Department Location\n",
      "0    Alice  30.00  50000.0         HR       NY\n",
      "1      Bob  33.75  60000.0         IT       CA\n",
      "2  Charlie  35.00  55000.0    Finance       TX\n",
      "3      Eve  40.00  70000.0         IT       WA\n",
      "\n",
      "Data after transformation:\n",
      "      Name    Age  Salary Department Location\n",
      "0    Alice  30.00    0.00         HR       NY\n",
      "1      Bob  33.75    0.50         IT       CA\n",
      "2  Charlie  35.00    0.25    Finance       TX\n",
      "3      Eve  40.00    1.00         IT       WA\n"
     ]
    }
   ],
   "source": [
    "# 3. Demonstrate data Preprocessing (Data Cleaning, Integration and Transformation) operations on a suitable data.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Sample data creation\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Eve'],\n",
    "    'Age': [30, None, 35, 30, 40],\n",
    "    'Salary': [50000, 60000, None, 50000, 70000],\n",
    "    'Department': ['HR', 'IT', 'Finance', 'HR', 'IT']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Data Cleaning\n",
    "# Handling missing values\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())  # Fill missing ages with mean age\n",
    "df['Salary'] = df['Salary'].fillna(df['Salary'].median())  # Fill missing salaries with median salary\n",
    "\n",
    "# Removing duplicate records\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(\"Data after cleaning:\")\n",
    "print(df)\n",
    "\n",
    "# 2. Data Integration\n",
    "# Create another simple dataset\n",
    "data2 = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Eve'],\n",
    "    'Location': ['NY', 'CA', 'TX', 'WA']\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Merge the datasets\n",
    "df_merged = pd.merge(df, df2, on='Name', how='left')\n",
    "\n",
    "print(\"\\nData after integration:\")\n",
    "print(df_merged)\n",
    "\n",
    "# 3. Data Transformation\n",
    "# Normalize the Salary column\n",
    "scaler = MinMaxScaler()\n",
    "df_merged['Salary'] = scaler.fit_transform(df_merged[['Salary']])\n",
    "\n",
    "print(\"\\nData after transformation:\")\n",
    "print(df_merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "877df016-bc54-49fb-86eb-f82c2c2689b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "Predicted labels: [1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0\n",
      " 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1]\n",
      "Actual labels: [1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0\n",
      " 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# 4. Demonstrate the working of SVM classifier for a suitable dataset.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "cancer = datasets.load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "# Train the classifier\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print predictions\n",
    "print(f\"Predicted labels: {pred}\")\n",
    "print(f\"Actual labels: {y_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2469cd60-298d-4bc9-b211-50b80b432a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n",
      "\n",
      "Decision Tree Rules:\n",
      "\n",
      "Predicted labels: [1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 0 0\n",
      " 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1]\n",
      "Actual labels: [1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0\n",
      " 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# 5. Implement and demonstrate the working of the Decision Tree algorithm.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "cancer = datasets.load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print predictions\n",
    "print(f\"Predicted labels: {y_pred}\")\n",
    "print(f\"Actual labels: {y_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c45af6b-9915-42be-a9a9-fbad511de364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96        63\n",
      "           1       0.96      0.99      0.98       108\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.97      0.96      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Implement Random Forest classifier using python programming.\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "cancer = datasets.load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "report = classification_report(y_test, pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c190f65a-9014-4fa9-9ff8-fdfa8f9f597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00         1\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "Test Sentence: \"I am excited about learning machine learning\"\n",
      "Predicted Label: positive\n"
     ]
    }
   ],
   "source": [
    "# 7. Demonstrate the text classifier using Naive Bayes classifier algorithm.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'text': [\n",
    "        'I love programming in Python',\n",
    "        'Python is a great language',\n",
    "        'I hate bugs in my code',\n",
    "        'Debugging is fun sometimes',\n",
    "        'I enjoy learning new things',\n",
    "        'Sometimes I get frustrated with errors',\n",
    "        'Coding is a valuable skill',\n",
    "        'Syntax errors are annoying',\n",
    "        'I love solving problems with code',\n",
    "        'Errors can be very frustrating'\n",
    "    ],\n",
    "    'label': [\n",
    "        'positive',\n",
    "        'positive',\n",
    "        'negative',\n",
    "        'positive',\n",
    "        'positive',\n",
    "        'negative',\n",
    "        'positive',\n",
    "        'negative',\n",
    "        'positive',\n",
    "        'negative'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocess the text data\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n",
    "# Predict for a new test sentence\n",
    "test_sentence = [\"I am excited about learning machine learning\"]\n",
    "test_sentence_transformed = vectorizer.transform(test_sentence)\n",
    "prediction = clf.predict(test_sentence_transformed)\n",
    "\n",
    "print(f'Test Sentence: \"{test_sentence[0]}\"')\n",
    "print(f'Predicted Label: {prediction[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2897ea4a-9824-4945-9b0c-ca5328225389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      1.00      0.67         1\n",
      "    positive       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 8. Implement the Naive Bayesian classifier for a sample training data set stored as a .CSV file. \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('dataset8.csv')\n",
    "\n",
    "# Split the dataset into input features and target variable\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline that vectorizes the text, applies TF-IDF transformation, and then fits a Naive Bayes classifier\n",
    "model = make_pipeline(CountVectorizer(), TfidfTransformer(), MultinomialNB())\n",
    "\n",
    "# Train the classifier\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Display a classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c5ca0a9-0810-4fd0-9038-b529677985fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3423f5a21b3a46a19d833c1b85de6d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab642bfecf740b282287be3830501f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnosis Prediction: {'heart_disease': 1}\n",
      "+---------+----------+\n",
      "| age(45) | 0.166667 |\n",
      "+---------+----------+\n",
      "| age(50) | 0.166667 |\n",
      "+---------+----------+\n",
      "| age(55) | 0.166667 |\n",
      "+---------+----------+\n",
      "| age(60) | 0.166667 |\n",
      "+---------+----------+\n",
      "| age(65) | 0.166667 |\n",
      "+---------+----------+\n",
      "| age(70) | 0.166667 |\n",
      "+---------+----------+\n",
      "+------------------+-----+---------------------+\n",
      "| age              | ... | age(70)             |\n",
      "+------------------+-----+---------------------+\n",
      "| blood_pressure   | ... | blood_pressure(160) |\n",
      "+------------------+-----+---------------------+\n",
      "| cholesterol      | ... | cholesterol(270)    |\n",
      "+------------------+-----+---------------------+\n",
      "| heart_disease(0) | ... | 0.0                 |\n",
      "+------------------+-----+---------------------+\n",
      "| heart_disease(1) | ... | 1.0                 |\n",
      "+------------------+-----+---------------------+\n",
      "+---------------------+----------+\n",
      "| blood_pressure(110) | 0.166667 |\n",
      "+---------------------+----------+\n",
      "| blood_pressure(120) | 0.166667 |\n",
      "+---------------------+----------+\n",
      "| blood_pressure(130) | 0.166667 |\n",
      "+---------------------+----------+\n",
      "| blood_pressure(140) | 0.166667 |\n",
      "+---------------------+----------+\n",
      "| blood_pressure(150) | 0.166667 |\n",
      "+---------------------+----------+\n",
      "| blood_pressure(160) | 0.166667 |\n",
      "+---------------------+----------+\n",
      "+------------------+----------+\n",
      "| cholesterol(190) | 0.166667 |\n",
      "+------------------+----------+\n",
      "| cholesterol(200) | 0.166667 |\n",
      "+------------------+----------+\n",
      "| cholesterol(220) | 0.166667 |\n",
      "+------------------+----------+\n",
      "| cholesterol(240) | 0.166667 |\n",
      "+------------------+----------+\n",
      "| cholesterol(250) | 0.166667 |\n",
      "+------------------+----------+\n",
      "| cholesterol(270) | 0.166667 |\n",
      "+------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "# 9. Construct a Bayesian network to analyze the diagnosis of heart patients using heart diseases dataset.\n",
    "\n",
    "# pip install pgmpy\n",
    "\n",
    "import pandas as pd\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "from pgmpy.inference import BeliefPropagation\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'age': [50, 60, 45, 55, 65, 70],\n",
    "    'blood_pressure': [120, 140, 110, 130, 150, 160],\n",
    "    'cholesterol': [200, 240, 190, 220, 250, 270],\n",
    "    'heart_disease': [0, 1, 0, 1, 1, 1]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the structure of the Bayesian Network\n",
    "model = BayesianNetwork([('age', 'heart_disease'), \n",
    "                         ('blood_pressure', 'heart_disease'),\n",
    "                         ('cholesterol', 'heart_disease')])\n",
    "\n",
    "# Fit the model using Maximum Likelihood Estimator\n",
    "model.fit(df, estimator=MaximumLikelihoodEstimator)\n",
    "\n",
    "# Inference\n",
    "inference = VariableElimination(model)\n",
    "query_result = inference.map_query(variables=['heart_disease'], evidence={'age': 60, 'blood_pressure': 140, 'cholesterol': 240})\n",
    "\n",
    "print(\"Diagnosis Prediction:\", query_result)\n",
    "\n",
    "# Display CPDs\n",
    "for cpd in model.get_cpds():\n",
    "    print(cpd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdcb22a8-2a34-4e17-9c92-8525976694a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pgmpy in /opt/anaconda3/lib/python3.11/site-packages (0.1.25)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from pgmpy) (3.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from pgmpy) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from pgmpy) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.11/site-packages (from pgmpy) (1.2.2)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (from pgmpy) (2.1.4)\n",
      "Requirement already satisfied: pyparsing in /opt/anaconda3/lib/python3.11/site-packages (from pgmpy) (3.0.9)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.11/site-packages (from pgmpy) (2.2.2)\n",
      "Requirement already satisfied: statsmodels in /opt/anaconda3/lib/python3.11/site-packages (from pgmpy) (0.14.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from pgmpy) (4.65.0)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.11/site-packages (from pgmpy) (1.2.0)\n",
      "Requirement already satisfied: opt-einsum in /opt/anaconda3/lib/python3.11/site-packages (from pgmpy) (3.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->pgmpy) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->pgmpy) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->pgmpy) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->pgmpy) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/anaconda3/lib/python3.11/site-packages (from statsmodels->pgmpy) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/lib/python3.11/site-packages (from statsmodels->pgmpy) (23.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch->pgmpy) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch->pgmpy) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch->pgmpy) (1.12)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch->pgmpy) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch->pgmpy) (2023.10.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.11/site-packages (from patsy>=0.5.2->statsmodels->pgmpy) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch->pgmpy) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch->pgmpy) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pgmpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "125e23a9-4d21-4e74-a768-415f99e41011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.90      0.94        63\n",
      "      benign       0.95      0.99      0.97       108\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.95      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10. Implement KNN classification algorithm with an appropriate dataset and analyze the results.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data  # Features\n",
    "y = cancer.target  # Target labels\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "# Use k=5 for this example; you can adjust k based on your needs\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Display a classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=cancer.target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c648fa-d6e7-4149-a1f9-7edb883cda89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
